# -*- coding: utf-8 -*-
"""MTS_0802.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_RpzsRyTpZMvnWULedfI37GNYIbadk6Q
"""

pip install cwru_py3

pip install acoustics

# Commented out IPython magic to ensure Python compatibility.
import cwru_py3 as cwru
# import cwru                      # Case Western Reserve University Bearing Data
import pandas as pd              # dataframe
import numpy as np               # array
from collections import Counter  # Class 갯수 세기
import matplotlib.pyplot as plt  # Visualization
# %matplotlib inline
from scipy.fftpack import fft, ifft
from acoustics.cepstrum import complex_cepstrum, real_cepstrum
from sklearn.preprocessing import scale, StandardScaler
from scipy.spatial import distance
from numpy.linalg import inv
from scipy.io import loadmat

cwru_data = cwru.CWRU("12DriveEndFault", "1750", 12000)
# "12DriveEndFault", "1750", 12000

cwru_data.labels

x_train = np.asarray(cwru_data.X_train)
x_test = np.asarray(cwru_data.X_test)

y_train = np.asarray(cwru_data.y_train)
y_test = np.asarray(cwru_data.y_test)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

# Normal 클래스
normal_train_idx, = np.where(y_train == 15)
normal_test_idx, = np.where(y_test == 15)

# Ball 클래스
ball_train_idx, = np.where((y_train == 0) | (y_train == 5) | (y_train == 8) | (y_train == 13))
ball_test_idx, = np.where((y_test == 0) | (y_test == 5) | (y_test == 8) | (y_test == 13))

# InnerRace 클래스
inner_train_idx, = np.where((y_train == 1) | (y_train == 6) | (y_train == 9) | (y_train == 14))
inner_test_idx, = np.where((y_test == 1) | (y_test == 6) | (y_test == 9) | (y_test == 14))

# Outer 클래스
outer_train_idx, = np.where((y_train == 2) | (y_train == 3) | (y_train == 4) | (y_train == 7) | (y_train == 10) | (y_train == 11) | (y_train == 12))
outer_test_idx, = np.where((y_test == 2) | (y_test == 3) | (y_test == 4) | (y_test == 7) | (y_test == 10) | (y_test == 11) | (y_test == 12))

# Train 데이터 클래스 수정
for i in range(len(y_train)):
    if i in normal_train_idx:
        y_train[i] = 0 # Normal 클래스
    elif i in ball_train_idx:
        y_train[i] = 1 # Ball 클래스
    elif i in inner_train_idx:
        y_train[i] = 2 # InnerRace 클래스
    elif i in outer_train_idx:
        y_train[i] = 3 # Outer 클래스
                
# Test 데이터 클래스 수정
for i in range(len(y_test)):
    if i in normal_test_idx:
        y_test[i] = 0 # Normal 클래스
    elif i in ball_test_idx:
        y_test[i] = 1 # Ball 클래스
    elif i in inner_test_idx:
        y_test[i] = 2 # InnerRace 클래스
    elif i in outer_test_idx:
        y_test[i] = 3 # Outer 클래스

np.random.seed(392)
#192, 392

x_train_normal_idx, = np.where(y_train==0)
x_test_normal_idx, = np.where(y_test==0)

x_train_normal_idx = np.random.choice(x_train_normal_idx, 20, replace=False)
x_test_normal_idx = np.random.choice(x_test_normal_idx, 10, replace=False)

# Ball
x_train_ball_idx, = np.where(y_train==1)
x_test_ball_idx, = np.where(y_test==1)
x_train_ball_idx = np.random.choice(x_train_ball_idx, 7, replace=False)
x_test_ball_idx = np.random.choice(x_test_ball_idx, 5, replace=False)

# Inner
x_train_inner_idx, = np.where(y_train==2)
x_test_inner_idx, = np.where(y_test==2)
x_train_inner_idx = np.random.choice(x_train_inner_idx, 7, replace=False)
x_test_inner_idx = np.random.choice(x_test_inner_idx, 5, replace=False)

# Outer
x_train_outer_idx, = np.where(y_train==3)
x_test_outer_idx, = np.where(y_test==3)
x_train_outer_idx = np.random.choice(x_train_outer_idx, 6, replace=False)
x_test_outer_idx = np.random.choice(x_test_outer_idx, 5, replace=False)

## Concat
x_train_abnormal_idx = np.concatenate((x_train_ball_idx, x_train_inner_idx, x_train_outer_idx))
x_test_abnormal_idx = np.concatenate((x_test_ball_idx, x_test_inner_idx, x_test_outer_idx))

x_train_normal = x_train[x_train_normal_idx]
y_train_normal = y_train[x_train_normal_idx]
x_train_abnormal = x_train[x_train_abnormal_idx]
y_train_abnormal = y_train[x_train_abnormal_idx]

x_test_normal = x_test[x_test_normal_idx]
y_test_normal = y_test[x_test_normal_idx]
x_test_abnormal = x_test[x_test_abnormal_idx]
y_test_abnormal = y_test[x_test_abnormal_idx]

print(x_train_normal.shape)
print(y_train_normal.shape)
print(x_train_abnormal.shape)
print(y_train_abnormal.shape)

print(x_test_normal.shape)
print(y_test_normal.shape)
print(x_test_abnormal.shape)
print(y_test_abnormal.shape)

for i in range(0, len(y_train_abnormal)):
  y_train_abnormal[i] = 1

for i in range(0, len(y_test_abnormal)):
  y_test_abnormal[i] = 1

def do_FFT(signal_set):
    window = np.hamming(12000)
    fft_rlt = np.fft.fft(window * signal_set)
    return(fft_rlt)

def do_Cepstrum(spectrum):
    cep_result = (ifft(np.log(spectrum**2))**2).real
    return(cep_result)

# Sample signal
sample_signal = x_train_normal[0]
time = np.linspace(0, 1, 12000)

# plot rsa
plt.figure(figsize = (10,5))
plt.plot(time, sample_signal)
#plt.title('Sample Signal')
plt.ylabel('Amplitude (mm/s^2)')
plt.xlabel('Time (s)')
plt.grid()

# Sample signal
sample_signal = x_train_normal[0]*np.hamming(12000)
time = np.linspace(0, 1, 12000)

# plot rsa
plt.figure(figsize = (10,5))
plt.plot(time, sample_signal)
#plt.title('Sample Signal')
plt.ylabel('Amplitude (mm/s^2)')
plt.xlabel('Time (s)')
plt.grid()

# Standardization
normal_x_train_scaled = pd.DataFrame(scale(x_train_normal, axis = 1))
normal_x_test_scaled = pd.DataFrame(scale(x_test_normal, axis = 1))

abnormal_x_train_scaled = pd.DataFrame(scale(x_train_abnormal, axis = 1))
abnormal_x_test_scaled = pd.DataFrame(scale(x_test_abnormal, axis = 1))

#Hamming and FFT
normal_x_train_fft = np.apply_along_axis(do_FFT, 1, normal_x_train_scaled)
normal_x_test_fft = np.apply_along_axis(do_FFT, 1, normal_x_test_scaled)

abnormal_x_train_fft = np.apply_along_axis(do_FFT, 1, abnormal_x_train_scaled)
abnormal_x_test_fft = np.apply_along_axis(do_FFT, 1, abnormal_x_test_scaled)

Fs = 12000.0;  # sampling rate
Ts = 1.0/Fs; # sampling interval
t = np.arange(0,1,Ts) # time vector

y = normal_x_train_scaled.iloc[0,:]

n = len(y) # length of the signal
# print(range(n/2))
k = np.arange(n)
T = n/Fs
frq = k/T # two sides frequency range
frq = frq[range(int(n/2))] # one side frequency range

Y = np.fft.fft(y)/n # fft computing and normalization
Y = Y[range(int(n/2))]

fig, ax = plt.subplots(2, 1)
ax[0].plot(t,y)
ax[0].set_xlabel('Time')
ax[0].set_ylabel('Amplitude')
ax[1].plot(frq,abs(Y),'r') # plotting the spectrum
ax[1].set_xlabel('Freq (Hz)')
ax[1].set_ylabel('|Y(freq)|')

#Cepstrum
normal_x_train_cep = np.apply_along_axis(do_Cepstrum, 1, normal_x_train_fft)
normal_x_test_cep = np.apply_along_axis(do_Cepstrum, 1, normal_x_test_fft)

abnormal_x_train_cep = np.apply_along_axis(do_Cepstrum, 1, abnormal_x_train_fft)
abnormal_x_test_cep = np.apply_along_axis(do_Cepstrum, 1, abnormal_x_test_fft)

plt.plot(normal_x_train_cep[0])

#SI Functions
def get_mean(x):
    avg = np.mean(x)
    return(avg)

def get_std(x):
    std = np.std(x)
    return(std)

def get_skewness(x):
    skewness = sum((x - np.mean(x))**3) / ((len(x)-1)*(np.std(x)**3))
    return(skewness)

def get_kurtosis(x):
    kurtosis = sum((x - np.mean(x))**4) / ((len(x)-1)*(np.std(x)**4))
    return (kurtosis)

def get_p2p(x):
    p2p = (np.max(x) - np.min(x))
    return(p2p)

def get_rms(x):
    rms = np.sqrt(sum(x**2) / len(x))
    return(rms)

def get_crestFactor(x):
    crestFactor = get_p2p(x) / get_rms(x)
    return(crestFactor)

def get_shapeFactor(x):
    shapeFactor = get_rms(x) / get_mean(x)
    return(shapeFactor)
    
def get_marginFactor(x):
    marginFactor = np.max(x) / (np.mean((np.sqrt(abs(x))))**2)
    return(marginFactor)

def get_impulseFactor(x):
    impulseFactor = np.max(x) / np.mean(abs(x))
    return(impulseFactor)

def make_df(x):
    mean_value = np.apply_along_axis(get_mean, 1, x)
    std_value = np.apply_along_axis(get_std, 1, x)
    skewness_value = np.apply_along_axis(get_skewness, 1, x)
    kurtosis_value = np.apply_along_axis(get_kurtosis, 1, x)
    p2p_value = np.apply_along_axis(get_p2p, 1, x)
    rms_value = np.apply_along_axis(get_rms, 1, x)
    crestFactor_value = np.apply_along_axis(get_crestFactor, 1, x)
    shapeFactor_value = np.apply_along_axis(get_shapeFactor, 1, x)
    marginFactor_value = np.apply_along_axis(get_marginFactor, 1, x)
    impulseFactor_value = np.apply_along_axis(get_impulseFactor, 1, x)
    
    df = pd.DataFrame({'mean':mean_value, 'std':std_value, 'skewness':skewness_value, 'kurtosis':kurtosis_value, 'p2p':p2p_value, 'rms':rms_value,
                       'crest':crestFactor_value, 'shape':shapeFactor_value, 'margin':marginFactor_value, 'impulse':impulseFactor_value})
    
    return(df)

#make dataframe
normal_x_train_SI = make_df(normal_x_train_cep)
normal_x_test_SI = make_df(normal_x_test_cep)

abnormal_x_train_SI = make_df(abnormal_x_train_cep)
abnormal_x_test_SI = make_df(abnormal_x_test_cep)

# normal_x_train_SI.to_csv('./normal_x_train_SI_0802.csv')
# normal_x_test_SI.to_csv('./normal_x_test_SI_0802.csv')
# abnormal_x_train_SI.to_csv('./abnormal_x_train_SI_0802.csv')
# abnormal_x_test_SI.to_csv('./abnormal_x_test_SI_0802.csv')

print(normal_x_train_SI)
print(normal_x_test_SI)

print(abnormal_x_train_SI)
print(abnormal_x_test_SI)

#Standardization in MTS
def standardize(x,y):
    mean_mean = get_mean(x['mean'])
    std_mean = get_mean(x['std'])
    skewness_mean = get_mean(x['skewness'])
    kurtosis_mean = get_mean(x['kurtosis'])
    p2p_mean = get_mean(x['p2p'])
    rms_mean = get_mean(x['rms'])
    crest_mean = get_mean(x['crest'])
    shape_mean = get_mean(x['shape'])
    margin_mean = get_mean(x['margin'])
    impulse_mean = get_mean(x['impulse'])
    
    mean_std = get_std(x['mean'])
    std_std = get_std(x['std'])
    skewness_std = get_std(x['skewness'])
    kurtosis_std = get_std(x['kurtosis'])
    p2p_std = get_std(x['p2p'])
    rms_std = get_std(x['rms'])
    crest_std = get_std(x['crest'])
    shape_std = get_std(x['shape'])
    margin_std = get_std(x['margin'])
    impulse_std = get_std(x['impulse'])
    
    mean_value = (y['mean'] - mean_mean) / mean_std
    std_value = (y['std'] - std_mean) / std_std
    skewness_value = (y['skewness'] - skewness_mean) / skewness_std
    kurtosis_value = (y['kurtosis'] - kurtosis_mean) / kurtosis_std
    p2p_value = (y['p2p'] - p2p_mean) / p2p_std
    rms_value = (y['rms'] - rms_mean) / rms_std
    crest_value = (y['crest'] - crest_mean) / crest_std
    shape_value = (y['shape'] - shape_mean) / shape_std
    margin_value = (y['margin'] - margin_mean) / margin_std
    impulse_value = (y['impulse'] - impulse_mean) / impulse_std
    
    df = pd.DataFrame({'mean':mean_value, 'std':std_value, 'skewness':skewness_value, 'kurtosis':kurtosis_value, 'p2p':p2p_value, 'rms':rms_value,
                       'crest':crest_value, 'shape':shape_value, 'margin':margin_value, 'impulse':impulse_value})
    
    return(df)

normal_x_train_SI_scaled = standardize(normal_x_train_SI, normal_x_train_SI)
normal_x_test_SI_scaled = standardize(normal_x_train_SI, normal_x_test_SI)

abnormal_x_train_SI_scaled = standardize(normal_x_train_SI, abnormal_x_train_SI)
abnormal_x_test_SI_scaled = standardize(normal_x_train_SI, abnormal_x_test_SI)

normal_x_train_SI_scaled.to_csv('./normal_x_train_SI_scaled_0802.csv')
normal_x_test_SI_scaled.to_csv('./normal_x_test_SI_scaled_0802.csv')

abnormal_x_train_SI_scaled.to_csv('./abnormal_x_train_SI_scaled_0802.csv')
abnormal_x_test_SI_scaled.to_csv('./abnormal_x_test_SI_scaled_0802.csv')

normal_cov_mat = pd.DataFrame(normal_x_train_SI_scaled).corr()
normal_cov_mat.to_csv('./normal_cov_mat_0802.csv')

def get_MD_distance(x):
    normal_cov_mat = pd.DataFrame(normal_x_train_SI_scaled).corr()
    dist = np.matmul(np.matmul(x, inv(normal_cov_mat)), np.transpose(x)) / len(x)
    return(dist)

normal_train_dist = np.apply_along_axis(get_MD_distance, 1, normal_x_train_SI_scaled)
normal_test_dist = np.apply_along_axis(get_MD_distance, 1, normal_x_test_SI_scaled)

abnormal_train_dist = np.apply_along_axis(get_MD_distance, 1, abnormal_x_train_SI_scaled)
abnormal_test_dist = np.apply_along_axis(get_MD_distance, 1, abnormal_x_test_SI_scaled)

print(normal_train_dist)
print('\n')
print(normal_test_dist)
print('\n')
print(abnormal_train_dist)
print('\n')
print(abnormal_test_dist)

#L_12(2^11) orthogonal array
# ortho_array = np.matrix([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
#                        [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2],
#                        [1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2],
#                        [1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2],
#                        [1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1],
#                        [1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1],
#                        [2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1],
#                        [2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2],
#                        [2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1],
#                        [2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2],
#                        [2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2],
#                        [2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1]])

#Plackett–Burman design
ortho_array = np.matrix([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                         [2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2],
                         [2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1],
                         [1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2],
                         [2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2],
                         [2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2],
                         [2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1],
                         [1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1],
                         [1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1],
                         [1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2],
                         [2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1],
                         [1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2]])

otho_df = pd.DataFrame(ortho_array, columns=['mean', 'std', 'skewness', 'kurtosis', 'p2p', 'rms', 'crest', 'shape', 'margin', 'impulse','DUMMY'])

def get_exp_col(n):
    condition = otho_df.iloc[n,:]==1
    col = list(otho_df.loc[n,condition].index)
    if('DUMMY' in col):
        col.pop()
    return(col)

def get_MD_distance_exp(x,n):
    col = get_exp_col(n)
    normal_cov_mat = pd.DataFrame(normal_x_train_SI_scaled[col]).corr()
    dist = np.matmul(np.matmul(x, inv(normal_cov_mat)), np.transpose(x)) / len(x)
    return(dist)

def get_MD_exp(n,df):
    col = get_exp_col(n)
    target_df = df[col]
    dist = np.apply_along_axis(get_MD_distance_exp, 1, target_df, n)
    return(dist)

def get_MD_matrix(df):
    arr = np.empty([12, df.shape[0]])
    for i in range(0,12):
        arr[i,:] = get_MD_exp(i,df)
        
    return(arr)

normal_x_train_MD_matrix = get_MD_matrix(normal_x_train_SI_scaled)
normal_x_test_MD_matrix = get_MD_matrix(normal_x_test_SI_scaled)

abnormal_x_train_MD_matrix = get_MD_matrix(abnormal_x_train_SI_scaled)
abnormal_x_test_MD_matrix = get_MD_matrix(abnormal_x_test_SI_scaled)

# print(normal_x_train_MD_matrix)
# print(normal_x_test_MD_matrix)

# print(abnormal_x_train_MD_matrix)
# print(abnormal_x_test_MD_matrix)

def cal_larger_better_SNRatio(mat):
    SNRatio = []
    for i in range(0, mat.shape[0]):
        dist = mat[i]
        SN = -10 * np.log10(np.mean(1/(dist)))
        SNRatio.append(SN)
        
    return(SNRatio)

def cal_smaller_better_SNRatio(mat):
    SNRatio = []
    for i in range(0,mat.shape[0]):
        dist = mat[i]
        SN = -10 * np.log10(np.mean(dist))
        SNRatio.append(SN)
        
    return(SNRatio)

SNRatio_normal_train = cal_larger_better_SNRatio(normal_x_train_MD_matrix)
SNRatio_normal_test = cal_larger_better_SNRatio(normal_x_test_MD_matrix)

SNRatio_abnormal_train = cal_larger_better_SNRatio(abnormal_x_train_MD_matrix)
SNRatio_abnormal_test = cal_larger_better_SNRatio(abnormal_x_test_MD_matrix)

print(SNRatio_normal_train)
# print(SNRatio_normal_test)
# print(SNRatio_abnormal_train)
# print(SNRatio_abnormal_test)

def cal_smaller_better_gain(mat, col_name):
    idx_1 = list(otho_df.loc[otho_df[col_name] == 1].index)
    idx_2 = list(otho_df.loc[otho_df[col_name] == 2].index)
    
    SN = np.array(cal_smaller_better_SNRatio(mat))
    values_1 = np.mean(SN[idx_1])
    values_2 = np.mean(SN[idx_2])
    
    gain = values_1 - values_2
    print('values_1', values_1)
    print('values_2', values_2)

    return(gain)

def cal_larger_better_gain(mat,col_name):
    idx_1 = list(otho_df.loc[otho_df[col_name] == 1].index)
    idx_2 = list(otho_df.loc[otho_df[col_name] == 2].index)
    
    SN = np.array(cal_larger_better_SNRatio(mat))
    values_1 = np.mean(SN[idx_1])
    values_2 = np.mean(SN[idx_2])
    
    gain = values_1 - values_2
    print('values_1', values_1)
    print('values_2', values_2)
    
    
    return(gain)

#get gain
column_names=['mean', 'std', 'skewness', 'kurtosis', 'p2p', 'rms', 'crest', 'shape', 'margin', 'impulse']

def get_normal_train_gain(col):
    columns = col
    gain_values = []
    for i in range(0,len(columns)):
        gain_values.append(cal_larger_better_gain(normal_x_train_MD_matrix, columns[i]))
        
    return(gain_values)

def get_normal_test_gain(col):
    columns = col
    gain_values = []
    for i in range(0,len(columns)):
        gain_values.append(cal_larger_better_gain(normal_x_test_MD_matrix, columns[i]))
        
    return(gain_values)
 
def get_abnormal_train_gain(col):
    columns = col
    gain_values = []
    for i in range(0,len(columns)):
        gain_values.append(cal_larger_better_gain(abnormal_x_train_MD_matrix, columns[i]))
        
    return(gain_values)

def get_abnormal_test_gain(col):
    columns = col
    gain_values = []
    for i in range(0,len(columns)):
        gain_values.append(cal_larger_better_gain(abnormal_x_test_MD_matrix, columns[i]))
        
    return(gain_values)

normal_train_gain = get_normal_train_gain(column_names)
# print('\n')
# normal_test_gain = get_normal_test_gain(column_names)
# print('\n')

# abnormal_train_gain = get_abnormal_train_gain(column_names)
# print('\n')
# abnormal_test_gain = get_abnormal_test_gain(column_names)

print('normal_train_gain')
print(pd.DataFrame(normal_train_gain, index=column_names))
# print('\n')

# print('normal_test_gain')
# print(pd.DataFrame(normal_test_gain, index=column_names))
# print('\n')

# print('abnormal_train_gain')
# print(pd.DataFrame(abnormal_train_gain, index=column_names))
# print('\n')

# print('abnormal_test_gain')
# print(pd.DataFrame(abnormal_test_gain, index=column_names))

# Select variables that show positive SN ratio in Normal test
# 'mean', 'std', 'skewness', 'kurtosis', 'p2p', 'rms', 'crest', 'shape', 'margin', 'impulse'

variables = ['mean', 'std', 'skewness', 'kurtosis', 'shape', 'margin', 'impulse']

normal_train_taguchi = normal_x_train_SI_scaled[variables]
normal_test_taguchi = normal_x_test_SI_scaled[variables]

abnormal_train_taguchi = abnormal_x_train_SI_scaled[variables]
abnormal_test_taguchi = abnormal_x_test_SI_scaled[variables]

def get_MD_distance_taguchi(x):
    normal_cov_mat = pd.DataFrame(normal_train_taguchi).corr()
    dist = np.matmul(np.matmul(x, inv(normal_cov_mat)), np.transpose(x)) / len(x)
    return(dist)

normal_train_dist_taguchi = np.apply_along_axis(get_MD_distance_taguchi, 1, normal_train_taguchi)
# normal_train_dist_taguchi.sort()
normal_test_dist_taguchi = np.apply_along_axis(get_MD_distance_taguchi, 1, normal_test_taguchi)
# normal_test_dist_taguchi.sort()

abnormal_train_dist_taguchi = np.apply_along_axis(get_MD_distance_taguchi, 1, abnormal_train_taguchi)
# abnormal_train_dist_taguchi.sort()
abnormal_test_dist_taguchi = np.apply_along_axis(get_MD_distance_taguchi, 1, abnormal_test_taguchi)
# abnormal_test_dist_taguchi.sort()

# Results of Feature selection
print('Normal Train (Mahalanobis Space)')
print(normal_train_dist_taguchi)
print('\n')

print('Normal Test')
print(normal_test_dist_taguchi)
print('\n')

print('Abnormal Train')
print(abnormal_train_dist_taguchi)
print('\n')

print('Abnormal Test')
print(abnormal_test_dist_taguchi)



"""# **ML 검증**"""

from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, balanced_accuracy_score, roc_auc_score
from sklearn.metrics import confusion_matrix

from scipy.stats import randint as sp_randint
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV

x_train_combined = np.concatenate((normal_x_train_SI, abnormal_x_train_SI), axis=0)
x_test_combined = np.concatenate((normal_x_test_SI, abnormal_x_test_SI), axis=0)

y_train_combined = np.concatenate((y_train_normal, y_train_abnormal))
y_test_combined = np.concatenate((y_test_normal, y_test_abnormal))

scaler = StandardScaler()

x_train_combined_scaled = scaler.fit_transform(x_train_combined)
x_test_combined_scaled = scaler.transform(x_test_combined)

"""**SVM**"""

# SVM
SVM_model =svm.SVC(probability=True), class_weight={[0:1, 1:1], [0:1, 1:6.667]}
SVM_model.fit(x_train_combined_scaled, y_train_combined)

param_dist = {"C" : [0.1, 0.3, 0.5, 0.75, 1, 1.5],
              "gamma": np.arange(0.1, 1, 0.2),
              'kernel': ['linear', 'rbf', 'poly']
              }

n_iter_search = 100
# random_search = RandomizedSearchCV(SVM_model, param_distributions=param_dist, n_iter=n_iter_search)
random_search = GridSearchCV(SVM_model, param_distributions=param_dist, n_iter=n_iter_search)
random_search.fit(x_train_combined_scaled, y_train_combined)

# 최적 파라미터 값
random_search.best_estimator_

# 2차 모델 구축
SVM_model2 = svm.SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
                     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',
                     max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,
                     verbose=False)
SVM_model2.fit(x_train_combined_scaled, y_train_combined)

y_pred = SVM_model2.predict(x_test_combined_scaled)
y_pred_prob = SVM_model2.predict_proba(x_test_combined_scaled)
y_scores = y_pred_prob[:,1]

# Confusion Matrix 생성
Confusion_Matrix = confusion_matrix(y_test_combined, y_pred)
print("Confusin Matrix : ")
print(Confusion_Matrix)

# Performance
acc_ = accuracy_score(y_test_combined, y_pred)
balanced_acc_ = balanced_accuracy_score(y_test_combined, y_pred)
recall_ = recall_score(y_test_combined, y_pred)
precision_ = precision_score(y_test_combined, y_pred)
f1_score_ = f1_score(y_test_combined, y_pred)
specificity = Confusion_Matrix[0,0]/(Confusion_Matrix[0,0] + Confusion_Matrix[0,1])
gmean = np.sqrt(specificity*recall_)
auc_ = roc_auc_score(y_test_combined, y_scores)

print("acc = ", acc_)
print("balanced_acc = ", balanced_acc_)
print("recall = ", recall_)
print("precision = ", precision_)
print("specificity = ", specificity)
print("f1_score = ", f1_score_)
print("gmean = ", gmean)
print("auc = ", auc_)



"""**RF**"""

# Random Forest
RF_model = RandomForestClassifier(), class_weight={[0:1, 1:1], [0:1, 1:6.667]}
RF_model.fit(x_train_combined_scaled, y_train_combined)

param_dist = {"n_estimators" : [50, 100, 300, 500]}

n_iter_search = 100
random_search = RandomizedSearchCV(RF_model, param_distributions=param_dist, n_iter=n_iter_search)
random_search.fit(x_train_combined_scaled, y_train_combined)

# 2차 모델 구축
RF_model2 = RandomForestClassifier(bootstrap=True,
                                   ccp_alpha=0.0,
                                   class_weight=None,
                                   criterion='gini',
                                   max_depth=None,
                                   max_features='auto',
                                   max_leaf_nodes=None,
                                   max_samples=None,
                                   min_impurity_decrease=0.0,
                                   min_impurity_split=None,
                                   min_samples_leaf=1,
                                   min_samples_split=2,
                                   min_weight_fraction_leaf=0.0,
                                   n_estimators=100,
                                   n_jobs=None,
                                   oob_score=False,
                                   random_state=None,
                                   verbose=0,
                                   warm_start=False)
RF_model2.fit(x_train_combined_scaled, y_train_combined)

y_pred = RF_model2.predict(x_test_combined_scaled)
y_pred_prob = RF_model2.predict_proba(x_test_combined_scaled)
y_scores = y_pred_prob[:,1]

# Confusion Matrix 생성
Confusion_Matrix = confusion_matrix(y_test_combined, y_pred)
print("Confusin Matrix : ")
print(Confusion_Matrix)

# Performance
acc_ = accuracy_score(y_test_combined, y_pred)
balanced_acc_ = balanced_accuracy_score(y_test_combined, y_pred)
recall_ = recall_score(y_test_combined, y_pred)
precision_ = precision_score(y_test_combined, y_pred)
f1_score_ = f1_score(y_test_combined, y_pred)
specificity = Confusion_Matrix[0,0]/(Confusion_Matrix[0,0] + Confusion_Matrix[0,1])
gmean = np.sqrt(specificity*recall_)
auc_ = roc_auc_score(y_test_combined, y_scores)

print("acc = ", acc_)
print("balanced_acc = ", balanced_acc_)
print("recall = ", recall_)
print("precision = ", precision_)
print("specificity = ", specificity)
print("f1_score = ", f1_score_)
print("gmean = ", gmean)
print("auc = ", auc_)











